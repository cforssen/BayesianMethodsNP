{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- See deadline on the course web page\n",
    "- This problem set is solved individually. See examination rules on the course web page and the explanation of the examination procedure below.\n",
    "- The two notebooks for each problem set contain a number of basic and extra problems; you can choose which and how many to work on. The extra problems are usually more challenging.\n",
    "- Students are allowed to discuss together and help each other when solving the problems. However, every student must understand their submitted solution in the sense that they should be able to explain and discuss them with a peer or with a teacher.\n",
    "- While discussions with your peers are allowed (and even encouraged), direct plagiarism is not. Every student must reach their own understanding of submitted solutions according to the definition in the previous point.\n",
    "- The use of coding assistance from code generating artificial intelligence tools is allowed. However, every student must reach their own understanding of submitted solutions (including employed algorithms) according to the definition above.\n",
    "- Some problems include checkpoints in the form of `assert` statements. These usually check some basic functionality and you should make sure that your code passes these statements without raising an `AssertionError`. \n",
    "- Do not use other python modules than the ones included in the `environment.yml` file in the course github repo. \n",
    "\n",
    "- **Important:** The grading of problem sets requires **all** of the following actions:\n",
    "  1. Make sure to always complete **Task 0** in the header part of the notebook and that this part does not raise any `AssertionError`(s).\n",
    "  1. **Complete** the corresponding questions in Yata for every task that you have completed. This usually involves copying and pasting some code from your solution notebook and passing the code tests. You need to have a green check mark on Yata to get the corresponding points.\n",
    "  1. **Upload** your solution in the form of your edited version of this Jupyter notebook via the appropriate assignment module in Canvas (separate for basic and extra tasks). It is the code and results in your submitted notebook that is considered to be your hand-in solution.\n",
    "  1. If selected, be **available for a discussion** of your solution with one of the teachers on the Monday afternoon exercise session directly following the problem set deadline. No extra preparation is needed for these discussions apart from familiarity with your own solution. A list of randomly selected students will be published on the course web page around Monday noon. During the afternoon session that same day, students will be called in the numbered order until the end of the list (or the end of the exercise session). You must inform the responsible teacher as soon as possible following the publication of the student list if you can not be physically present at the exercise session (in which case we will have the discussion on zoom). An oral examination (on all aspects of the course) will be arranged during the exam week for students that do not show up for their discussion slot, or that fail to demonstrate familiarity with their hand-in solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "- Make sure that the **run time is smaller than a few minutes**. If needed you might have to reduce some computational tasks; e.g. by decreasing the number of grid points or sampling steps. Please ask the supervisors if you are uncertain about the run time. \n",
    "\n",
    "- Your solutions are usually expected where it says `YOUR CODE HERE` or <font color=\"red\">\"PLEASE WRITE YOUR ANSWER HERE\"</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0 \n",
    "#### (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "251105c400969a6d24e9f7ec4883888e",
     "grade": false,
     "grade_id": "cell-6f99a2583f9fb27d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "By changing the below boolean variable `student_self_assessment` to `True` you attest that:\n",
    "- All handed in solutions were produced by yourself in the sense that you understand your solutions and should be able to explain and discuss them with a peer or with a teacher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64a7020fd0e62e5b51ef4470ae1c797f",
     "grade": false,
     "grade_id": "student-self-assessment",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "student_self_assessment = False\n",
    "\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d873afed15d2d3de2ef460d53fccf90f",
     "grade": true,
     "grade_id": "cell-795bedd2908899aa",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert student_self_assessment == True, 'You must assert the individual solution statements.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1\n",
    "## Basic problems\n",
    "### Learning from data [TIF285], Chalmers, Fall 2023\n",
    "\n",
    "Last revised: 18-Aug-2023 by Christian Forssen [christian.forssen@chalmers.se]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations\n",
    "Perform the installations and preparations that are described in the Getting Started instructions. At the end you should have:\n",
    "\n",
    "1. downloaded the current version of the course material from the github repository or from the course web page;\n",
    "2. a running python installation that includes the modules listed in the environment.yml file (e.g. numpy, matplotlib, pandas, emcee, scikit-learn, ...);\n",
    "3. been able to open and run the Jupyter Notebooks with the first week exercises.\n",
    "Ask the computer lab supervisors for assistance if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cffc7d4975be42d36ea3279085c8bcee",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Modules needed for tests and file system operations\n",
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "# Where to save the figures and data files\n",
    "DATA_ID = \"DataFiles/\"\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "# Make sure that you are running python with version >= 3.x\n",
    "#\n",
    "# Import the following python modules with\n",
    "# the specified abreviations:\n",
    "# ---\n",
    "# numpy as np\n",
    "# scipy as scipy\n",
    "# scipy.stats as stats\n",
    "# pandas as pd\n",
    "# matplotlib.pyplot as plt\n",
    "# sklearn as skl\n",
    "# emcee as emcee\n",
    "\n",
    "\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6a82073d8b8c74026808c8bacccad6d",
     "grade": true,
     "grade_id": "correct_import",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "assert sys.version_info.major>=3, \\\n",
    "    'You are running Python version'+\\\n",
    "    f'{sys.version_info.major}.{sys.version_info.minor}'\n",
    "\n",
    "modules = [('numpy','np'), ('scipy', 'scipy'), \\\n",
    "           ('pandas', 'pd'), ('matplotlib.pyplot', 'plt'), \\\n",
    "           ('sklearn', 'skl'), ('emcee', 'emcee')]\n",
    "for (_module, _module_abbrev) in modules:\n",
    "    assert _module in sys.modules and _module_abbrev in dir(),\\\n",
    "        f'Module {_module} not loaded properly.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random samples\n",
    "In this course there are $N$ students and three problem sets.\n",
    "The random selection of students for problem set discussions is performed by drawing $N$ samples of three random variables $(X_1, X_2, X_3)$. These are arranged in an array of shape (N,3) as follows \n",
    "$$\n",
    "\\left(\n",
    "\\begin{array}{ccc}\n",
    "x_1(1) & x_2(1) & x_3(1) \\\\\n",
    "x_1(2) & x_2(2) & x_3(2) \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "x_1(N) & x_2(N) & x_3(N)\n",
    "\\end{array}\n",
    "\\right).\n",
    "$$\n",
    "The students with the lowest values of the respective random variable will then be invited for discussions with a teaching assistant. E.g., for problem set 1 there will be an ordered list of students $(k, l, m, \\ldots)$, where $x_1(k) < x_1(l) < x_1(m) < \\ldots$.\n",
    "\n",
    "It is considered fair that all students have the same probability to draw at least one small number, but it should be less likely to draw two small numbers. This can be achieved by making the random variables dependent, more specifically by making the covariance negative (anticorrelated). Here we use a correlated, multivariate Gaussian\n",
    "$$\n",
    "(X_1, X_2, X_3) \\sim \\mathcal{N}\\left( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} \\right),\n",
    "$$\n",
    "with mean and covariance\n",
    "$$\n",
    "\\boldsymbol{\\mu} = (0,0,0),\\quad\n",
    "\\boldsymbol{\\Sigma} = \\left(\n",
    "\\begin{array}{ccc}\n",
    "1 & -0.49 & -0.49 \\\\\n",
    "-0.49 & 1 & -0.49 \\\\\n",
    "-0.49 & -0.49 & 1\n",
    "\\end{array}\n",
    "\\right),\n",
    "$$ \n",
    "which means that every univariate, marginal distribution will be a standard normal ($\\mu=0, \\sigma^2=1$).\n",
    "\n",
    "Take a minute to consider the reason for making the random variables anticorrelated (it is instructive to visualize the multivariate distribution) and the fact that the correlation factor cannot be more negative than -0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (see also Yata):** Consider a class with 6 students. Use the method `multivariate_normal` from `scipy.stats` and generate an array of shape (6,3) with samples from the distribution defined in Problem 1. Print the result. \n",
    "\n",
    "*Important*: Use the random seed 2023 when generating the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c013c5f1717d83336961f1ad005a36c",
     "grade": false,
     "grade_id": "P1array",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (see also Yata):** Create a `Pandas.DataFrame` with the sample array from the previous task. The columns should be labeled ['X1', 'X2', 'X3'] while the row indices should be ['Student 1', 'Student 2', 'Student 3', ...]. Print the DataFrame (in the notebook you can try the more fancy option `display`, while you should use `print` on Yata).\n",
    "\n",
    "Assume that only the first two students from each ordered list are selected. Which student(s) will not be selected for any of the problem sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b566ad5dce8ad7a797ac9f7dc9130a2",
     "grade": false,
     "grade_id": "P1df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "201685d3f87893b93945cfc2be15aaa8",
     "grade": false,
     "grade_id": "P2generate",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate noisy data with a quadratic feature\n",
    "# use the following code:\n",
    "np.random.seed(42)\n",
    "m = 100 # Number of data\n",
    "\n",
    "# X are picked uniform random [0,2]\n",
    "X = 2 * np.random.rand(m, 1)\n",
    "# Linear relation to the predicted value, but with Gaussian noise (mean=0, standard deviation=0.2)\n",
    "theta_true = [0.25, 1, 0.75]\n",
    "noise_std = 0.2\n",
    "y = theta_true[2] * X**2 + theta_true[1] * X + theta_true[0] +  np.random.normal(loc=0.0, scale=noise_std, size=(m,1))\n",
    "\n",
    "# Below is a hidden code block that is used in the solution notebook to save the data. \n",
    "# \n",
    "# Please ignore the comment in this cell that says \"YOUR CODE HERE\". It gets added automatically.\n",
    "# No solution code is needed here.\n",
    "#\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear regression using the Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (see also Yata):** Create a python function `design_matrix` that returns the design matrix for a polynomial model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f281da58c59dffe144d18c64b30cf347",
     "grade": false,
     "grade_id": "design_matrix",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def design_matrix(X, degree=2):\n",
    "    \"\"\"\n",
    "    Returns a design matrix.\n",
    "    \n",
    "    Args:\n",
    "        X: Array of shape (m,1) with 'm' independent data.\n",
    "        degree: Integer with the degree of the polynomial. \n",
    "                  Note that a degree-n polynomial has n+1 coefficients.\n",
    "                  \n",
    "    Returns:\n",
    "        X_d: Design matrix of shape (m, order+1).\n",
    "    \"\"\"\n",
    "    # \n",
    "    # YOUR CODE HERE\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df0b83f3837a71a88749810d0a538cdf",
     "grade": true,
     "grade_id": "correct_design_matrix",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "assert design_matrix(X).shape == (len(X),3)\n",
    "assert design_matrix(X)[:,0].all() == 1\n",
    "assert design_matrix(X)[0,1] == X[0]\n",
    "assert design_matrix(X)[0,2] == X[0]**2\n",
    "\n",
    "ratio = design_matrix(X)[:,2]/design_matrix(X)[:,1]**2\n",
    "assert ratio.all() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (see also Yata):** Complete the python method `solve_normal_equation` that solves the normal equation using matrix inversion. This function can be used to fit a quadratic model to the data generated for this problem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "350da970376594885f058c64685baf17",
     "grade": false,
     "grade_id": "solve_normal_equation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def solve_normal_equation(X_d, y):\n",
    "    \"\"\"\n",
    "    Solve the normal equation.\n",
    "    \n",
    "    Args:\n",
    "        X_d: Design matrix of shape (m,n) with 'm' independent data\n",
    "               and 'n' features.\n",
    "        y: Dependent data of shape (m,1).\n",
    "                  \n",
    "    Returns:\n",
    "        theta_best: Best parameters, array of shape (n,).\n",
    "    \"\"\"\n",
    "    # \n",
    "    # YOUR CODE HERE\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "892303593d999820f79c3b78cab37b15",
     "grade": true,
     "grade_id": "correct_solve_normal_equation",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "assert (solve_normal_equation(design_matrix(X), y)).shape==(3,),\\\n",
    "    'Return object has wrong shape. Maybe the `flatten` method will be useful?'\n",
    "theta_star = np.array([0.36228054, 0.72777588, 0.86621274])\n",
    "theta_residuals = solve_normal_equation(design_matrix(X), y) - theta_star\n",
    "assert (abs(theta_residuals)<1e-7).all(), f'The solution to the normal equation is of low precision. theta_residulas = {abs(theta_residuals)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Gradient descent\n",
    "Gradient descent optimization is not really needed for linear regression since we can solve the normal equation exactly. However, it is instructive to implement it yourself and to be able to compare with a known solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (see also Yata)** \n",
    "Define a function to perform gradient descent optimization on a linear model that is defined by a design matrix and the data (see further instructions in the code cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a692178b37bed33f69931aeee313cea",
     "grade": false,
     "grade_id": "gradient_descent_function",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent_linear_regression(X_d, y, theta_start, eta=0.1, n_iterations=1000):\n",
    "    \"\"\"\n",
    "    Find optimized parameters in linear regression using (batch) gradient descent.\n",
    "    \n",
    "    Args:\n",
    "        X_d: Design matrix of shape (m,n) with 'm' independent data\n",
    "               and 'n' features (ndarray).\n",
    "        y: Dependent data of size m (ndarray).\n",
    "        theta_start: List-like initial guess for parameters (size n) \n",
    "        eta: learning rate (default 0.1) (float)\n",
    "        n_iterations: Number of iterations (epochs) (default 1000) (integer)\n",
    "                  \n",
    "    Returns:\n",
    "        theta_optimum: Optimized parameters, array of shape (n,).\n",
    "    \"\"\"\n",
    "    (m,n) = X_d.shape\n",
    "    assert len(y)==m, f'The size of y must be {m}. It is: {len(y)}.'\n",
    "    y = y.reshape(-1,1) # Turn into a (m,1) array.\n",
    "    assert len(theta_start)==n, f'The initial guess must be of size {n}. It is: {len(theta_start)}.'\n",
    "    \n",
    "    # \n",
    "    # YOUR CODE HERE\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae48d0f8a32a0bdbcb37813577cafb72",
     "grade": true,
     "grade_id": "correct_gradient_descent_function",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "assert (gradient_descent_linear_regression(design_matrix(X), y,[0,0,0],n_iterations=1)).shape==(3,),\\\n",
    "    'Return object has wrong shape. Maybe the `flatten` method will be useful?'\n",
    "X_d = np.c_[np.ones((m, 1)), X, X**2]\n",
    "# Solution to normal equation\n",
    "theta_star = np.array([0.36228054, 0.72777588, 0.86621274])\n",
    "# Check gradient\n",
    "gradient_optimum = theta_star - gradient_descent_linear_regression(X_d, y, theta_star,eta=1.0,n_iterations=1)\n",
    "assert (abs(gradient_optimum)<1e-7).all(), 'Gradient at optimum is not zero (elements > 10**-7)'\n",
    "# Check final optimum (tolerance 10**-2)\n",
    "theta_residuals = gradient_descent_linear_regression(X_d, y, [0,0,0]) - theta_star\n",
    "assert (abs(theta_residuals)<1e-2).all(), 'Residuals of GD optimum are too large (elements > 10**-2)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Comparison of solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks (see also Yata)** \n",
    "Apply both your solver of the normal equation and your gradient descent optimizer to the same data and quadratic model that was introduced at the beginning of this problem.\n",
    "- Print and compare the coefficients from (i) the true polynomial data generator to the linear regression fits to the (noisy) data from both (ii) the exact solution of the normal equation and (iii) the result of the gradient descent optimization. \n",
    "- Plot the data and the model predictions in the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "642a2f14e390bd0e2401bd8cf81d08ba",
     "grade": false,
     "grade_id": "cell-fbd1f3bdda876913",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1. Print and compare the coefficients from \n",
    "#   (i) the true data generator, \n",
    "#   (ii) the solution of the normal equation, \n",
    "#   (iii) the optimum from gradient descent.\n",
    "#\n",
    "# 2. Plot the data, the true model and the fit model predictions in the same figure.\n",
    "\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f523cfadaae0a17a63fbf834241101f",
     "grade": false,
     "grade_id": "cell-ad4ec88c445cd30c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There are three files in the directory `DataFiles`:\n",
    "- `dataset1.dat`\n",
    "- `dataset2.dat`\n",
    "- `dataset3.dat`\n",
    "\n",
    "Each data files contains two columns. The first column corresponds to the independent variables (the array X), and the second column corresponds to the dependent ones (the array y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a655d3c7ebb14f0a4df66ce2ab7daf8",
     "grade": false,
     "grade_id": "cell-a51f823aed196b24",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used in the solution notebook to generate and save the data. \n",
    "# It is hidden in the student version.\n",
    "# \n",
    "# Please ignore the comment in this cell that says \"YOUR CODE HERE\". It gets added automatically.\n",
    "# No solution code is needed here.\n",
    "# ---\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac8d0df0c393a85fe8b4d15485b019af",
     "grade": false,
     "grade_id": "cell-5f84c9fa34a2552c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (a) Implement linear regression and the MSE cost function for training and validation\n",
    "**Tasks (see also Yata for the final numerical comparison)** \n",
    "- Load a data set and split it into 60% training and 40% validation data using the python function below.\n",
    "- Implement a linear regression function that takes training data as input and returns a best-fit parameter vector for a polynomial model of a specified degree (see code template below).\n",
    "- Implement a cost function that takes data and model parameters as input and returns the mean-squared error (see code template below).\n",
    "- Apply this functionality to one of the datasets (see Yata for numerical checks).\n",
    "\n",
    "Hint: use the `design_matrix` and `solve_normal_equation` methods from Problem 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b886fccdb06f514ef4e964cc065d9dc2",
     "grade": false,
     "grade_id": "cell-a53c70d002ece548",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# built-in convenience function for splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(datafile, train_size=0.6):\n",
    "    \"\"\"\n",
    "    Reads data from file and returns training and validation sets.\n",
    "    \n",
    "    Args:\n",
    "        datafile: String with data filename path. The data file \n",
    "            should contain two columns: x, y\n",
    "        train_size: float indicating the fraction of training data\n",
    "            (default: 0.6)\n",
    "            \n",
    "    Returns:\n",
    "        (X_train, X_val, y_train, y_val): Tuple with four arrays \n",
    "            with training and validation data.\n",
    "    \"\"\"\n",
    "    X, y = np.loadtxt(datafile, unpack=True)\n",
    "    m = len(X)\n",
    "    X = X.reshape(m,1); y = y.reshape(m,1)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = \\\n",
    "        train_test_split(X, y, train_size=train_size, random_state=42)\n",
    "    return (X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5efdb5f19bfa224686f5f393f22e0fca",
     "grade": false,
     "grade_id": "cell-aa16bd9e1a61d370",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement a linear regression function that takes \n",
    "# training data as input and returns a best-fit parameter \n",
    "# vector for a polynomial model of a specified degree.\n",
    "def linear_regression(X, y, degree=2):\n",
    "    \"\"\"\n",
    "    Performs linear regression for a polynomial model.\n",
    "    \n",
    "    Args:\n",
    "        X: Array of shape (m,1) with 'm' independent data.\n",
    "        y: Array of shape (m,1) with 'm' dependent data.\n",
    "        degree: Integer with the degree of the polynomial. \n",
    "                  Note that a degree-n polynomial has n+1 coefficients.\n",
    "                  \n",
    "    Returns:\n",
    "        theta_fit: Best fit parameters. Array of shape (degree+1,)\n",
    "    \"\"\"\n",
    "    # \n",
    "    # YOUR CODE HERE\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d0367f0796324ae56503c7e37b83107",
     "grade": true,
     "grade_id": "cell-b26c3f6a60009e39",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "datafile = f'{DATA_ID}/PS1_Prob3_dataset1.txt'\n",
    "(X_train, X_val, y_train, y_val) = load_data(datafile)\n",
    "assert len(linear_regression(X_train, y_train, degree=3))==4\n",
    "a0_degree3fit_residual = \\\n",
    "    linear_regression(X_train, y_train, degree=3)[0] - 0.04772979\n",
    "assert abs(a0_degree3fit_residual) < 1e-5\n",
    "\n",
    "datafile = f'{DATA_ID}/PS1_Prob3_dataset3.txt'\n",
    "(X_train, X_val, y_train, y_val) = load_data(datafile)\n",
    "theta_star_degree4fit = np.array([ 1.42786627,  2.92656911,  0.9522876 , \\\n",
    "                                  -0.38212683, -0.00978446])\n",
    "theta_residuals = linear_regression(X_train, y_train, degree=4).reshape(-1,) \\\n",
    "    - theta_star_degree4fit\n",
    "assert (abs(theta_residuals)<1e-5).all(), print('theta_residuals=\\n',theta_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d6e7a52e9f29ba4f3d25fe3a4e48b7e",
     "grade": false,
     "grade_id": "MSE",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement a cost function that takes data and polynomial model \n",
    "# parameters as input and returns the mean-squared error.\n",
    "def mean_squared_error(X, y, theta):\n",
    "    \"\"\"\n",
    "    Compute the mean-squared error for data and a polynomial fit.\n",
    "    \n",
    "    Args:\n",
    "        X: Array of shape (m,1) with 'm' independent data.\n",
    "        y: Array of shape (m,1) with 'm' dependent data.\n",
    "        theta: Parameter array [shape (degree+1,)]. \n",
    "            The ordering corresponds to the constant term first.\n",
    "            \n",
    "    Return:\n",
    "        MSE (float): Mean-squared error defined as\n",
    "            MSE = (1/m) * sum_i (y[i] - y_model[i])**2,\n",
    "            where y_model[i] = \\sum_m theta[m]*X[i]**m \n",
    "    \"\"\"\n",
    "    # \n",
    "    # YOUR CODE HERE\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "X_train=np.array([[1],[2],[3]])\n",
    "y_train=np.array([[2],[5],[10]])\n",
    "assert mean_squared_error(X_train, y_train, np.array([1,0,1]))==0\n",
    "assert mean_squared_error(X_train, y_train, np.array([0,0,0]))==43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6ad3069ead763efbfe6d9ded05f17f9",
     "grade": false,
     "grade_id": "polynomial_regression",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement a function that takes training and validation data plus \n",
    "# polynomial model degree as input, performs the optimization to \n",
    "# the training data and returns the mean-squared error for both training \n",
    "# and validation data as well as the best fit parameters.\n",
    "def polynomial_regression( data, degree):\n",
    "    \"\"\"\n",
    "    Compute the mean-squared error for data and a polynomial fit.\n",
    "    \n",
    "    Args:\n",
    "        data = (X_train, X_val, y_train, y_val): Tuple with four arrays \n",
    "            with training and validation data.\n",
    "        degree: Integer with the degree of the polynomial. \n",
    "                  Note that a degree-n polynomial has n+1 coefficients.\n",
    "            \n",
    "    Return:\n",
    "        MSE_train: Mean-squared error of training data\n",
    "        MSE_val: Mean-squared error of validation data\n",
    "        theta_fit: Best fit parameters [array of shape (degree+1,)]\n",
    "    \"\"\"\n",
    "    # \n",
    "    # YOUR CODE HERE\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6245c16d62d7a4e0c73e68a8aa84a83f",
     "grade": true,
     "grade_id": "correct_MSE",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "X_val = np.array([[4],[5]])\n",
    "y_val = np.array([[17],[27]])\n",
    "MSE_train, MSE_val, theta_fit = \\\n",
    "    polynomial_regression( (X_train, X_val, y_train, y_val), 2)\n",
    "assert MSE_val-0.5 < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final, numerical results. \n",
    "# See also Yata\n",
    "datafile = f'{DATA_ID}/PS1_Prob3_dataset3.txt'\n",
    "(X_train, X_val, y_train, y_val) = load_data(datafile)\n",
    "degrees = range(6)\n",
    "print('Model degree  MSE(train)    MSE(val)')\n",
    "for degree in degrees:\n",
    "    MSE_train, MSE_val, theta_fit = \\\n",
    "        polynomial_regression( (X_train, X_val, y_train, y_val), degree)\n",
    "    print(f'{degree:>12}{\"\":5}{MSE_train:7.3f}{\"\":5}{MSE_val:7.3f}  {theta_fit[0]} {theta_fit[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "datafile = f'{DATA_ID}/PS1_Prob3_dataset3.txt'\n",
    "(X_train, X_val, y_train, y_val) = load_data(datafile)\n",
    "MSE_train, MSE_val, theta_fit = \\\n",
    "    polynomial_regression( (X_train, X_val, y_train, y_val), 4)\n",
    "assert abs(MSE_train-3.8740275553091648)<1e-5\n",
    "assert abs(MSE_val-2.2031653660595256)<1e-5\n",
    "assert abs(theta_fit[0]-1.4278662700653606)<1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3abb216a22a2989745111ee8fb8dd784",
     "grade": false,
     "grade_id": "cell-0a736787d7c078d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (b) Train and validate linear regression with different polynomial models\n",
    "**Tasks (see also Yata)** \n",
    "- For each data set you should then perform linear regression using polynomial models of order 1,2,3,4,5, and 20.\n",
    "- Finally, print the fit coefficients for each polynomial model that was considered and print also the mean-squared error (MSE) for both the training and the validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "898c9652ff10c9817d46d55d5be266d9",
     "grade": false,
     "grade_id": "cell-49fbcaec1138af05",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "867e8588d935d41dbc08ff3598b06088",
     "grade": false,
     "grade_id": "cell-fcfe8b4f88e942d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (c) Concluding discussion\n",
    "**Tasks (see also Yata)** \n",
    "Answer the following two questions:\n",
    "- Which degrees of polynomials do you think was used for generating the different datasets?\n",
    "- Which dataset do you think has the most noise?\n",
    "\n",
    "You should be able to discuss your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "277d1fd74970f3566c89480f97e43d5e",
     "grade": true,
     "grade_id": "cell-93dac302fd63f96a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used only in the solution notebook.\n",
    "# \n",
    "# Please ignore the comment in this cell that says \"YOUR CODE HERE\". It gets added automatically.\n",
    "# No solution code is needed here.\n",
    "# ---\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Applying Bayesian rules of probability to a standard medical example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "047732edfc9bef96df36ebc94305b8c7",
     "grade": false,
     "grade_id": "cell-a717eb4d32ba845e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Suppose there is an unknown disease (call it UD) that does not give any symptoms in its early phase, but that there is a test for it.\n",
    "\n",
    "a. The false positive rate is 2.3%. (\"False positive\" means the test says you have UD, but you don't.) <br>\n",
    "b. The false negative rate is 1.4%. (\"False negative\" means you have UD, but the test says you don't.)\n",
    "\n",
    "Assume that 1 in 10,000 people have the disease. You are given the test and get a positive result.  Your ultimate goal is to find the probability that you actually have the disease. \n",
    "$% Some LaTeX definitions we'll use.\n",
    "\\newcommand{\\pr}{\\textrm{p}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e3d6d1a8635628beb75d133afccc515",
     "grade": false,
     "grade_id": "cell-51752b16483bb655",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll do it using the Bayesian rules.\n",
    "\n",
    "We'll use the notation:\n",
    "\n",
    "* $H$ = \"you have UD\"\n",
    "* $\\overline H$ = \"you do not have UD\"  \n",
    "* $D$ = \"you test positive for UD\"\n",
    "* $\\overline D$ = \"you test negative for UD\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e62ca260750658aa3c7f5783c560dc8",
     "grade": false,
     "grade_id": "cell-61c95058fe103533",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Tasks (see also Yata)** \n",
    "\n",
    "Answer the following questions. Some of them are repeated on Yata.\n",
    "\n",
    "a. *Before doing a calculation (or thinking too hard :), does your intuition tell you the probability you have the disease is high or low?*\n",
    "<br>\n",
    "\n",
    "b. *In the $p(\\cdot | \\cdot)$ notation, what is your ultimate goal?*\n",
    "<br>\n",
    "\n",
    "c. *Express the false positive rate in $p(\\cdot | \\cdot)$ notation.* \\[Ask yourself first: what is to the left of the bar?\\]\n",
    "<br>\n",
    "\n",
    "d. *Express the false negative rate in $p(\\cdot | \\cdot)$ notation. By applying the sum rule, what do you also know? (If you get stuck answering the question, do the next part first.)* \n",
    "<br>\n",
    "\n",
    "e. *Should $p(D|H) + p(D|\\overline H) = 1$?\n",
    "    Should $p(D|H) + p(\\overline D |H) = 1$?\n",
    "    (Hint: does the sum rule apply on the left or right of the $|$?)*\n",
    "<br>\n",
    "\n",
    "f. *Apply Bayes' theorem to your result for your ultimate goal (don't put in numbers yet).\n",
    "   What other probabilities do we need?*\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eeccf4e51901f05414de6f2de3386574",
     "grade": false,
     "grade_id": "bayes_medical",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used only in the solution notebook.\n",
    "# \n",
    "# Please ignore the comment in this cell that says \"YOUR CODE HERE\". It gets added automatically.\n",
    "# No solution code is needed here.\n",
    "# ---\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Applying Bayesian rules of probability to a standard medical example (cont.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks (see also Yata)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c26443747ad7abc8240520552e29550",
     "grade": false,
     "grade_id": "medical_example",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please fill the probabilities as values for the \n",
    "# corresponding keys in the following dictionary.\n",
    "medical_example_probabilities = {}\n",
    "medical_example_probabilities['p(D|Hbar)'] = 0.0\n",
    "medical_example_probabilities['p(Dbar|H)'] = 0.0\n",
    "medical_example_probabilities['p(D|H)'] = 0.0\n",
    "medical_example_probabilities['p(H,Hbar|D)'] = 0.0\n",
    "medical_example_probabilities['p(Hbar)'] = 0.0\n",
    "medical_example_probabilities['p(D)'] = 0.0\n",
    "medical_example_probabilities['p(H|D)'] = 0.0\n",
    "\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ed248809a8371c7e567206cc9226d26",
     "grade": true,
     "grade_id": "correct_1_medical_example",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for key in ['p(D|Hbar)', 'p(Dbar|H)', 'p(D|H)']:\n",
    "    assert medical_example_probabilities[key] > 0.\n",
    "    assert medical_example_probabilities[key] < 1.\n",
    "    \n",
    "assert medical_example_probabilities['p(H,Hbar|D)'] <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f767d6ab42f1573d59d64de9f207cec",
     "grade": true,
     "grade_id": "correct_2_medical_example",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for key in ['p(Hbar)', 'p(D)', 'p(H|D)']:\n",
    "    assert medical_example_probabilities[key] > 0.\n",
    "    assert medical_example_probabilities[key] < 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
